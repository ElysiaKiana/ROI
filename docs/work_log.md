# 第一章：感知降维 —— 基于非对称双流与 CAA 注意力的轻量级多模态 ROI 生成

## 工作记录与改进说明

> 本文档详细记录了 ROI 生成网络从 v1 到 v2 的所有设计、实验与改进过程，旨在为论文写作提供完整的数据支撑。

---

## 1. 系统总览

### 1.1 核心目标

在无人机端搭载的 NVIDIA Jetson Xavier NX（15W, ~21 TOPS INT8）上，设计一个**极轻量级（< 1 GFLOPs）**的多模态深度学习网络，从 RGB + IR 双模态图像中生成包含"人 + 武器"的紧凑 ROI 切片，供后续第二章（YOLO/VLM 级联推理）和第三章（PPO-Mix3 计算卸载）使用。

### 1.2 网络架构

```
IR Image (B,1,H,W)  ──→ IRBranch (3层CNN)  ──→ (B,32,H/4,W/4)  ─┐
                                                                    ├→ Concat → CAA → SaliencyHead → (B,1,H,W)
RGB Image (B,3,H,W) ──→ RGBBranch (MNv3-S) ──→ (B,32,H/4,W/4)  ─┘
```

| 组件 | 设计 | 作用 |
|------|------|------|
| **IR 分支** | 3 层 Conv-BN-ReLU (stride=2,1,2) | 从红外图像提取热源锚点特征 |
| **RGB 分支** | MobileNetV3-Small 前 4 层 + 1×1 Conv | 提取高频边缘纹理，利用 ImageNet 预训练 |
| **CAA 模块** | 条带卷积 (1×11, 11×1) + 通道注意力 | 学习热源-武器空间语义关联 |
| **融合策略** | 通道拼接 (Concat) + CAA 加权 | 保留双模态独立信息，自适应融合 |
| **显著性头** | 3×3 Conv + 1×1 Conv → 双线性上采样 | 输出原图尺寸的显著性图 |

### 1.3 计算量与参数量

```
FLOPs:  0.891 GFLOPs  (< 1 GFLOPs 预算 ✓)
Params: 0.040 M       (约 4 万参数)
```

---

## 2. 数据集：LLVIP

| 属性 | 数值 |
|------|------|
| 训练集 | 12,025 对 RGB+IR 图像 |
| 测试集 | 3,463 对 RGB+IR 图像 |
| 标注数 | 15,488 个 PASCAL VOC 格式 bbox |
| 标注类别 | 仅 `person`（行人） |
| 原始分辨率 | 1280 × 1024 |
| 训练分辨率 | 640 × 512 (W × H) |
| BBox 均值 | 97 × 226 px (原图尺度) |
| BBox 面积占比 | ~1.68%（严重的正负样本不平衡） |

---

## 3. 版本演进与改进详述

### 3.1 v1 基线实现

#### 3.1.1 GT 标签生成 (v1 — 硬矩形)

```python
# 策略: 将每个 bbox 区域直接填充 1.0
for x1, y1, x2, y2 in boxes:
    saliency[y1:y2, x1:x2] = 1.0
```

**问题分析:**
- 矩形框内包含大量背景像素，全部标为正样本（1.0），引入噪声监督
- 行人 bbox 通常宽高比悬殊（约 1:2.3），矩形两侧大量空白
- GT 覆盖率约 **6.5~8.3%**，虽然正样本占比小但信号质量差
- 硬边界（0→1 的突变）导致网络难以学习平滑的显著性过渡

#### 3.1.2 损失函数 (v1 — 标准 BCE)

```
L_total = 1.0 × BCE + 1.0 × Dice + 0.5 × IoU
```

**问题分析:**
- 标准 BCE 对所有样本等权处理，~93.5% 的背景像素主导梯度方向
- 网络倾向于预测全 0（保守策略），前景区域激活不足

#### 3.1.3 聚类与 ROI 切片 (v1 — 质心聚类)

- 从显著性图提取连通域后，**仅保留质心坐标**，丢弃 bbox 空间范围
- DBSCAN 对质心聚类后，使用固定像素外扩 (isolated: 30px, crowd: 80px)

**严重缺陷:** 由于质心周围没有 bbox 尺寸信息，外扩后大多数 ROI 退化为 `min_roi_size=64` 的固定方块。

#### 3.1.4 v1 训练结果

| 指标 | 训练集 | 验证集 |
|------|--------|--------|
| Epochs | 10 | - |
| Loss | 0.0576 | 0.0636 |
| Precision | 0.827 | 0.802 |
| Recall | 0.870 | 0.876 |
| **F1** | 0.846 | **0.836** |
| **IoU** | 0.734 | **0.720** |

> 注: v1 的 F1=0.836 看似不错，但这是因为硬矩形 GT 本身容易匹配（矩形区域内全为 1.0，阈值 0.5 即可命中）。实际显著性图质量很差——网络在非热源区域也产生强激活（如路灯、红绿灯）。

#### 3.1.5 v1 推理 ROI 质量诊断

对 3,463 张测试图推理后统计：

| 指标 | 数值 |
|------|------|
| 总 ROI 数 | 15,692 |
| 平均 ROI/帧 | 4.5 |
| **宽度 = 64px 的占比** | **91.4%** |
| 平均 ROI 尺寸 | 65 × 66 px |
| 最大 ROI 尺寸 | 640 × 321 px |

**核心问题:** 91% 的 ROI 为固定 64×64 小方块，这是因为 v1 聚类只用质心 + 固定外扩，目标实际空间范围被完全丢弃。

---

### 3.2 v2 改进方案

#### 3.2.1 改进一：高斯椭圆软标签 GT

**动机:** 替换硬矩形 GT 为 2D 高斯椭圆热图，让网络学到"中心强、边缘弱"的更合理显著性分布。

**技术细节:**

对每个 bbox $(x_1, y_1, x_2, y_2)$，生成 2D 高斯分布：

$$G(x, y) = \exp\left(-\frac{(x - \mu_x)^2}{2\sigma_x^2} - \frac{(y - \mu_y)^2}{2\sigma_y^2}\right)$$

其中：
- $\mu_x = (x_1 + x_2) / 2$，$\mu_y = (y_1 + y_2) / 2$（bbox 中心）
- $\sigma_x = \max(w \times r, 3)$，$\sigma_y = \max(h \times r, 3)$（$r = 0.3$ 为 sigma_ratio）
- 多目标取 element-wise max（不叠加，避免值超过 1）
- 仅在 $\pm 3\sigma$ 范围内计算（性能优化）

**可选 IR 亮度加权:**

$$S(x,y) = G(x,y) \times \left(0.5 + 0.5 \times I_{norm}(x,y)\right)$$

- $I_{norm}$ 为归一化到 [0,1] 的 IR 灰度图
- 人体热源处 IR 明亮 → 乘以接近 1.0 的权重 → 增强
- 冷背景处 IR 暗 → 乘以接近 0.5 的权重 → 适度抑制
- 下限 0.5 保证中心区域不会因暗区被完全压制

**GT 对比数据 (以第 010001 帧为例):**

| 属性 | v1 (硬矩形) | v2 (高斯) |
|------|-------------|-----------|
| GT 覆盖率 (>0.5) | 8.28% | 3.09% |
| GT 值域 | {0.0, 1.0} | [0.0, ~0.86] |
| 边界过渡 | 硬跳变 (0→1) | 平滑衰减 |
| 中心响应 | 均匀 1.0 | 峰值 ~0.86 (IR加权) |

#### 3.2.2 改进二：Focal Loss 替代标准 BCE

**动机:** LLVIP 中 GT 正样本覆盖率仅 ~3-8%，标准 BCE 被大量易分类背景像素主导。

**技术细节:**

$$L_{Focal} = -\alpha_t (1 - p_t)^\gamma \log(p_t)$$

| 参数 | 值 | 说明 |
|------|----|------|
| $\alpha$ | 0.75 | 正样本权重高（前景稀少） |
| $\gamma$ | 2.0 | RetinaNet 经典值，强调困难样本 |

完整损失函数：

$$L_{total} = 1.0 \times L_{Focal} + 1.0 \times L_{Dice} + 0.5 \times L_{IoU}$$

- $L_{Focal}$：逐像素加权，抑制易分类背景
- $L_{Dice}$：关注前景区域的整体重叠
- $L_{IoU}$：进一步约束交并比

#### 3.2.3 改进三：基于连通域 bbox 的空间密度聚类 (v2)

**动机:** v1 聚类丢弃目标空间范围，导致 91% ROI 为固定 64×64 小方块。

**v2 关键改进:**

| 对比维度 | v1 | v2 |
|----------|----|----|
| 连通域信息 | 仅保留质心 $(c_x, c_y)$ | 保留完整 bbox $(x_1, y_1, x_2, y_2)$ + 质心 + 面积 |
| 外扩策略 | 固定像素 (30px / 80px) | 自适应比例：$pad = \max(15, bbox\_size \times 0.3)$ |
| 聚集合并 | 质心外扩 → 容易遗漏目标 | 合并簇内所有 bbox → 完整覆盖 |
| ROI 尺寸 | 退化为 min_roi_size | 由实际目标范围决定 |

**聚类 v2 统计对比 (v1 模型权重不变，仅换聚类):**

| 指标 | v1 聚类 | v2 聚类 |
|------|---------|---------|
| 总 ROI 数 | 15,692 | 13,981 |
| 平均 ROI/帧 | 4.5 | 4.0 |
| 宽度=64 占比 | **91.4%** | **14.3%** |
| 平均 ROI 宽 | 65 px | 108 px |
| 平均 ROI 高 | 66 px | 145 px |

> 64×64 退化比例从 91% **暴降至 14%**，ROI 切片质量显著提升。

---

## 4. 诊断实验

### 4.1 深度学习 vs 简单处理 — 显著性图有效性验证

为验证网络是否真正学到了有意义的显著性模式（而非仅传递 IR 原图），设计对比实验：

| 对比条件 | Saliency 均值 | >0.5 覆盖率 | 结论 |
|----------|--------------|-------------|------|
| **训练权重** | 0.0996 | 9.9% | 结构化输出，聚焦热源区域 |
| **随机权重** | 0.5259 | 100% | 均匀噪声，无任何结构 |

结论：**训练后的网络确实学到了有意义的特征表示**，显著性图有清晰的目标激活模式，而非简单传递 IR 亮度。

### 4.2 GT v1 vs v2 可视化对比

| 对比项 | v1 (硬矩形) | v2 (高斯椭圆) |
|--------|-------------|---------------|
| 空间分布 | 矩形块状填充 | 椭圆高斯衰减 |
| 值域 | 二值 {0, 1} | 连续 [0, ~0.86] |
| 边界 | 硬跳变 | 平滑过渡 |
| IR 感知 | 无 | 热源增强、冷区抑制 |
| 背景噪声 | bbox 内大量背景=1 | 仅中心高响应 |

三组对比可视化已保存至 `outputs/diagnostics/gt_compare_*.png`。

---

## 5. v2 训练进展

### 5.1 训练配置

| 参数 | 值 |
|------|----|
| Epochs | 50 |
| Batch Size | 4 |
| Learning Rate | 0.001 → cosine decay |
| Weight Decay | 0.0001 |
| GT Mode | gaussian (σ_ratio=0.3, IR weighting) |
| Loss | Focal(α=0.75, γ=2.0) + Dice + IoU |
| Optimizer | AdamW |

### 5.2 训练曲线 (完整 23 轮，epoch 24 因 Windows 多进程问题崩溃)

| Epoch | Train Loss | Train F1 | Val Loss | Val F1 | Val IoU | Best? |
|-------|-----------|----------|----------|--------|---------|-------|
| 1 | 0.8932 | 0.483 | 0.8509 | 0.497 | 0.332 | ★ |
| 2 | 0.8335 | 0.510 | 0.8258 | 0.513 | 0.346 | ★ |
| 3 | 0.8238 | 0.517 | 0.8437 | 0.501 | 0.335 | |
| 4 | 0.8187 | 0.520 | 0.8218 | 0.518 | 0.350 | ★ |
| 5 | 0.8150 | 0.522 | 0.8385 | 0.505 | 0.338 | |
| 6 | 0.8123 | 0.524 | 0.8604 | 0.489 | 0.325 | |
| 7 | 0.8101 | 0.525 | 0.8276 | 0.515 | 0.347 | |
| 8 | 0.8094 | 0.526 | 0.8267 | 0.512 | 0.345 | |
| 9 | 0.8075 | 0.527 | 0.8080 | 0.525 | 0.357 | ★ |
| 10 | 0.8064 | 0.528 | 0.8078 | 0.526 | 0.357 | ★ |
| 11 | 0.8050 | 0.529 | 0.8025 | 0.530 | 0.361 | ★ |
| 12 | 0.8047 | 0.529 | 0.8040 | 0.529 | 0.360 | |
| 13 | 0.8027 | 0.530 | 0.8005 | 0.531 | 0.362 | ★ |
| 14 | 0.8023 | 0.530 | 0.8033 | 0.530 | 0.361 | |
| 15 | 0.8018 | 0.531 | 0.8095 | 0.524 | 0.356 | |
| 16 | 0.8013 | 0.531 | 0.8032 | 0.529 | 0.360 | |
| 17 | 0.8003 | 0.532 | 0.8078 | 0.525 | 0.357 | |
| 18 | 0.7995 | 0.532 | 0.8042 | 0.528 | 0.359 | |
| 19 | 0.7993 | 0.532 | 0.8077 | 0.525 | 0.357 | |
| 20 | 0.7985 | 0.533 | 0.7966 | 0.533 | 0.364 | ★ |
| 21 | 0.7983 | 0.533 | 0.7966 | 0.533 | 0.364 | ★ |
| 22 | 0.7980 | 0.533 | 0.7982 | 0.532 | 0.363 | |
| 23 | 0.7970 | 0.534 | 0.7955 | **0.534** | **0.365** | ★ |

### 5.3 关于 v1 与 v2 F1 值的可比性说明

v2 的 F1 (0.525) 表面看远低于 v1 (0.836)，但 **两者不可直接比较**，原因如下：

1. **GT 值域不同**: v1 GT 为二值 {0, 1}，v2 GT 为连续 [0, ~0.86]
2. **指标计算方式**: `compute_metrics` 对预测和 GT 都用 threshold=0.5 二值化
   - v1: GT 中 bbox 区域全为 1.0 → 阈值后覆盖率 ~8%
   - v2: GT 中只有高斯峰值 >0.5 → 阈值后覆盖率仅 ~3%
3. **学习难度差异**: 高斯软标签要求网络精确预测中心强度和空间衰减模式，比简单填充矩形困难得多
4. **实际显著性质量 v2 更优**: v2 训练的显著性图聚焦人体核心、避免路灯干扰，ROI 切片质量更高

> 建议后续补充 **MAE (Mean Absolute Error)** 和 **加权 F-measure** 等适合软标签评估的指标。

---

## 6. v2 推理结果与 v1 对比

### 6.1 ROI 整体统计

| 指标 | v1 Model | v2 Model | 变化 |
|------|----------|----------|------|
| 总 ROI 数 | 13,981 | 10,387 | **-25.7%** |
| 平均 ROI/帧 | 4.0 | 3.0 | -25.0% |
| 平均宽度 | 108.4 px | 95.9 px | -11.5% |
| 平均高度 | 144.8 px | 137.6 px | -5.0% |
| Width=64 占比 | 24.4% | 28.7% | +4.3pp |
| 平均 data_size_kb | 4.0 KB | 3.6 KB | -10.0% |
| 总传输量 | 54.4 MB | **36.9 MB** | **-32.2%** |
| Crowd ROI | 628 (4.5%) | 504 (4.9%) | —— |

> v2 模型使传输数据量减少 32%，直接降低了无人机回传带宽消耗。

### 6.2 行人覆盖率 (Person Recall) —— 核心评估指标

在 LLVIP 测试集上，检查每个 GT 标注行人是否被 ROI 覆盖：

| 指标 | v1 Model | v2 Model | 说明 |
|------|----------|----------|------|
| GT 行人总数 | 8,301 | 8,286 | 近似相等 |
| **中心覆盖率** | **97.5%** | **93.9%** | v1 因过度生成 ROI 而高 |
| **IoU≥0.3 覆盖率** | **39.4%** | **57.4%** | **v2 大幅提升 +18.0pp** |
| 全覆盖帧比例 | 94.2% | 86.9% | v2 更选择性 |

**关键解读:**
- **中心覆盖率**衡量"是否检测到目标"，两者都 >93%，满足需求
- **IoU≥0.3 覆盖率**衡量"ROI 是否精确覆盖目标"，**v2 提升 45.7% (相对)**
- v1 的高中心覆盖率靠"多发 ROI"支撑（4.0/帧 vs 3.0/帧），但 ROI 定位差
- v2 用更少的 ROI 实现了更好的覆盖质量

### 6.3 阈值敏感性分析 (500 帧子集)

| 阈值 | ROI/帧 | 中心召回率 | IoU≥0.3 召回率 |
|------|--------|-----------|---------------|
| 0.5 | 3.1 | 93.8% | 53.6% |
| 0.4 | 3.1 | 93.9% | 52.8% |
| 0.3 | 3.1 | 94.3% | 52.5% |
| 0.2 | 3.2 | 94.6% | 51.3% |

> v2 模型对阈值不敏感（ROI 数量在 0.2~0.5 范围内仅变化 3%），说明模型输出的置信度分布二极化（确定为人的区域 >0.5，确定不是的区域 <0.2），泛化稳定。

### 6.4 显著性图质量对比 (测试集 5 帧)

| 帧号 | v1 均值 | v1 覆盖(>0.5) | v2 均值 | v2 覆盖(>0.5) | 下降比 |
|------|---------|--------------|---------|--------------|--------|
| 190001 | 0.087 | 8.7% | 0.063 | 6.2% | -28.7% |
| 190101 | 0.100 | 9.9% | 0.063 | 6.4% | -35.4% |
| 190502 | 0.064 | 6.3% | 0.053 | 5.2% | -17.5% |
| 200174 | 0.030 | 2.8% | 0.013 | 1.3% | -53.6% |
| 230038 | 0.085 | 8.4% | 0.045 | 4.6% | -45.2% |

> v2 的显著性图覆盖面积平均减少 **36%**，表明模型更聚焦于人体区域，减少了对路灯、红绿灯等非目标热源的虚假激活。

---

## 7. 文件结构与代码说明

```
ROI/
├── models/
│   ├── ir_branch.py          # IR 分支: 3层CNN (1→16→32 channels)
│   ├── rgb_branch.py         # RGB 分支: MobileNetV3-Small 前4层 + 1×1 Conv
│   ├── caa_module.py         # CAA 上下文锚点注意力: 条带卷积 (1×11, 11×1)
│   ├── fusion.py             # 非对称融合: Concat → CAA → SaliencyHead → 上采样
│   └── roi_network.py        # 端到端组装: IR + RGB → 融合 → 显著性图
├── data/
│   ├── llvip_dataset.py      # LLVIP 数据加载 + GT 生成 (v1硬矩形 / v2高斯)
│   └── LLVIP/                # 数据集目录 (infrared/ + visible/ + Annotations/)
├── utils/
│   └── clustering.py         # 空间密度聚类 v2 (连通域bbox + DBSCAN + 自适应外扩)
├── configs/
│   ├── default.yaml          # 默认全量配置
│   ├── quick_train.yaml      # v1 快速训练配置 (10 epochs)
│   └── train_v2.yaml         # v2 训练配置 (50 epochs, Gaussian GT + Focal)
├── train.py                  # 训练脚本 (FocalLoss + DiceLoss + IoULoss)
├── inference.py              # 推理脚本 → ROI切片 + tasks.csv
├── visualize.py              # 可视化脚本
├── checkpoints/
│   ├── best.pth              # 当前最优模型 (v2 训练中)
│   └── best_v1.pth           # v1 最优模型备份
└── outputs/
    ├── tasks.csv             # 输出给第二三章的任务清单
    ├── roi_slices/           # ROI 切片图像
    ├── saliency_maps/        # 显著性热图可视化
    ├── visualizations/       # 综合可视化 (grid, detail, roi_crops)
    └── diagnostics/          # 诊断图像 (GT对比, 训练vs随机)
```

---

## 8. Bug 修复记录

| # | 问题 | 位置 | 修复 |
|---|------|------|------|
| 1 | `nn.AdaptiveAvgPool2d(None)` 报错 | `caa_module.py` | 改为 `nn.Identity()` |
| 2 | `count_flops()` CPU/GPU 张量不匹配 | `roi_network.py` | 获取 `device` 后创建 dummy tensor |
| 3 | thop 注入 buffer 污染 `state_dict` | `roi_network.py` | profile 后删除 `total_ops/total_params` |
| 4 | checkpoint 加载缺少预训练 key | `inference.py` | `weights_only=True, strict=False` |
| 5 | 显著性图尺寸不匹配原图 | `visualize.py` | 添加 `cv2.resize` 对齐 |

---

## 9. 创新点总结 (用于论文表述)

### 创新点 1: 非对称双流轻量级多模态融合网络

- **非对称设计**: IR 用极浅 3 层 CNN（~0.02 GFLOPs），RGB 用预训练 MobileNetV3-Small 前 4 层
- **理论依据**: IR 信息密度低（热源-背景对比强），无需深层网络；RGB 需要 ImageNet 预训练的纹理特征
- **总计算量 0.891 GFLOPs、参数 0.040M**，可部署在 Jetson Xavier NX 上

### 创新点 2: 上下文锚点注意力机制 (CAA)

- 用条带卷积 $(1 \times 11)$ 和 $(11 \times 1)$ 替代标准大核卷积
- 水平条带捕捉"人-枪"水平共现关系
- 垂直条带捕捉"人-刀"垂直共现关系
- 参数量从 $k^2 = 121$ 降至 $2k = 22$（深度可分离时）

### 创新点 3: 高斯椭圆热图 + IR 亮度加权 GT 生成策略

- 2D 高斯椭圆替代硬矩形 bbox 填充
- IR 亮度加权让网络学会区分"人体热源"与"设备热源"（路灯/红绿灯）
- 配合 Focal Loss 解决 97% 背景像素的严重不平衡

### 创新点 4: 自适应空间密度聚类 ROI 切片

- 保留连通域完整 bbox 信息（而非仅质心）
- 自适应外扩比例 $pad = \max(15, size \times 0.3)$
- 分离目标切小图、聚集目标 ($\geq 3$) 切大图
- 输出动态 `data_size_kb` 供第三章卸载调度使用

---

## 10. 待完成工作

- [ ] v2 训练恢复完成（从 epoch 24 继续到 50）
- [ ] 补充软标签指标: MAE、加权 F-measure ($F_\beta^w$)
- [ ] 可视化 v1 vs v2 显著性图逐帧对比（已完成 5 帧，可扩展）
- [ ] 在合成武器数据上验证 CAA 对"人-武器"关联的有效性
- [ ] 导出 ONNX 格式，测量 Jetson Xavier NX 实际推理延迟
- [ ] 生成最终 `tasks.csv` 交付给第二、三章
- [ ] 进一步优化：尝试动态阈值 / 更大 sigma_ratio 以提高中心召回率

---

## 附录 A: 诊断可视化文件清单

| 文件 | 说明 |
|------|------|
| `outputs/diagnostics/compare_trained_vs_random.png` | 训练权重 vs 随机权重显著性图对比 |
| `outputs/diagnostics/gt_compare_010001.png` | GT v1 vs v2 对比 (帧 010001) |
| `outputs/diagnostics/gt_compare_010051.png` | GT v1 vs v2 对比 (帧 010051) |
| `outputs/diagnostics/gt_compare_010101.png` | GT v1 vs v2 对比 (帧 010101) |
| `outputs/diagnostics/v1_vs_v2_190001.png` | v1 vs v2 显著性图四宫格对比 |
| `outputs/diagnostics/v1_vs_v2_190101.png` | v1 vs v2 显著性图四宫格对比 |
| `outputs/diagnostics/v1_vs_v2_190502.png` | v1 vs v2 显著性图四宫格对比 |
| `outputs/diagnostics/v1_vs_v2_200174.png` | v1 vs v2 显著性图四宫格对比 |
| `outputs/diagnostics/v1_vs_v2_230038.png` | v1 vs v2 显著性图四宫格对比 |

## 附录 B: 输出目录说明

| 目录 | 模型 | 文件数 |
|------|------|--------|
| `outputs_v1/` | v1 (Hard GT, 10 epochs) | 13,981 ROIs + 显著性图 |
| `outputs_v2/` | v2 (Gaussian GT, 23 epochs) | 10,387 ROIs + 显著性图 |
| `outputs_v1/tasks.csv` | v1 任务清单 | 供第二三章使用 |
| `outputs_v2/tasks.csv` | v2 任务清单 | 供第二三章使用 |

---

*最后更新: v2 训练 Epoch 23/50 (最佳 Val F1=0.5341)，训练恢复中*
