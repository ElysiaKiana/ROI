dataset:
  augment:
    horizontal_flip: true
    random_crop: false
    vertical_flip: false
  img_size:
  - 512
  - 640
  name: LLVIP
  root: ./data/LLVIP
  train_split: 0.8
model:
  caa:
    in_channels: 64
    reduction: 4
    strip_kernel: 11
  ir_branch:
    in_channels: 1
    mid_channels: 16
    num_layers: 3
    out_channels: 32
  rgb_branch:
    feature_layer: 4
    out_channels: 32
    pretrained: true
  saliency_head:
    in_channels: 64
    mid_channels: 32
    out_channels: 1
output:
  checkpoint_dir: ./checkpoints
  log_interval: 10
  save_dir: ./outputs
  save_interval: 2
roi:
  crowd_padding_ratio: 0.25
  crowd_threshold: 3
  dbscan_eps: 80
  dbscan_min_samples: 1
  jpeg_quality: 85
  min_area: 100
  min_padding: 15
  min_roi_size: 64
  padding_ratio: 0.3
  saliency_threshold: 0.5
training:
  batch_size: 4
  epochs: 10
  gamma: 0.1
  loss:
    bce_weight: 1.0
    dice_weight: 1.0
    iou_weight: 0.5
  lr: 0.001
  lr_scheduler: cosine
  num_workers: 2
  step_size: 30
  weight_decay: 0.0001
